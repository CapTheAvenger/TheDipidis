# ‚úÖ DEPLOYMENT CHECKLISTE

## 1Ô∏è‚É£ Git Repository Setup

- [ ] GitHub Desktop oder Git Bash installiert
- [ ] Repository geklont oder hochgeladen: https://github.com/captheavenger/HausiTCG
- [ ] `.git` Ordner existiert lokal
- [ ] Remote URL gesetzt: `origin ‚Üí captheavenger/HausiTCG`

## 2Ô∏è‚É£ Dateien korrekt strukturiert

- [ ] `.gitignore` vorhanden und korrekt
- [ ] `.github/workflows/daily-scrape.yml` vorhanden
- [ ] `.github/workflows/deploy-pages.yml` vorhanden
- [ ] Alle Settings-Dateien vorhanden:
  - [ ] `City_League_Archetype_Scraper/city_league_archetype_settings.json`
  - [ ] `Limitless_Online_Scraper/limitless_online_settings.json`
  - [ ] `Unified_Card_Scraper/unified_card_settings.json`
- [ ] Python-Dateien in Scrapern:
  - [ ] `City_League_Scraper/city_league_scraper.py`
  - [ ] `Limitless_Scraper/limitless_scraper.py`
  - [ ] `Limitless_Online_Scraper/limitless_online_scraper.py`
  - [ ] `Unified_Card_Scraper/unified_card_scraper.py`

## 3Ô∏è‚É£ EXE-Dateien (optional f√ºr GitHub)

- [ ] Entscheiden: EXEs hochladen oder nur Python-Dateien?
  - Option A: Nur Python (empfohlen) ‚Üí Aktualisiere `.gitignore`
  - Option B: EXEs hochladen ‚Üí Nutze GitHub Releases (nicht Git LFS)

## 4Ô∏è‚É£ GitHub Pages Konfiguration

- [ ] Gehe zu: https://github.com/captheavenger/HausiTCG/settings/pages
- [ ] "Source" = "GitHub Actions"
- [ ] Deploy Branch = `main`
- [ ] Custom Domain = nicht n√∂tig (standard: captheavenger.github.io/HausiTCG)

## 5Ô∏è‚É£ GitHub Actions aktivieren

- [ ] Gehe zu: https://github.com/captheavenger/HausiTCG/actions
- [ ] √úberpr√ºfe dass Workflows existieren:
  - [ ] `Daily Card Scraping (6:00 UTC)`
  - [ ] `Deploy GitHub Pages`
- [ ] Teste manuellen Trigger: Click "Run workflow"

## 6Ô∏è‚É£ Secrets (falls n√∂tig)

- [ ] √úberpr√ºfe ob API-Tokens n√∂tig sind
- [ ] Falls ja: Settings ‚Üí Secrets ‚Üí Actions
- [ ] F√ºge `GITHUB_TOKEN` oder andere Secrets hinzu

## 7Ô∏è‚É£ Lokaler Test BEFORE Push

```bash
# Teste die Scraper lokal vor GitHub
cd "C:\Users\haush\OneDrive\Desktop\Hausi Scrapen\Unified_Card_Scraper"
python unified_card_scraper.py

# √úberpr√ºfe ob Output-CSVs generiert werden
dir /B *.csv
```

## 8Ô∏è‚É£ Initial Push zu GitHub

```bash
git add .
git commit -m "üöÄ Initial commit: Complete scraper setup with GitHub Actions"
git branch -M main
git push -u origin main
```

## 9Ô∏è‚É£ Verifizierung auf GitHub

- [ ] Gehe zu: https://github.com/captheavenger/HausiTCG
- [ ] √úberpr√ºfe dass alle Dateien vorhanden sind
- [ ] Klick "Actions" tab
- [ ] F√ºhre "Daily Card Scraping" manuell aus: "Run workflow"
- [ ] Warte auf Completion (gr√ºner Haken)
- [ ] √úberpr√ºfe dass CSVs aktualisiert wurden

## üîü GitHub Pages Test

- [ ] Warte 1-2 Minuten nach erfolgreichem Push
- [ ] √ñffne: https://captheavenger.github.io/HausiTCG/deck_viewer.html
- [ ] Teste dass Deck Viewer funktioniert
- [ ] √úberpr√ºfe dass Bilder laden (Limitless CDN URLs)

## üìÖ Automatische Schedule aktivieren

- [ ] GitHub Actions sollte t√§glich um 6:00 UTC laufen
- [ ] Falls nicht: Gehe zu `.github/workflows/daily-scrape.yml` und √ºberpr√ºfe Cron:
  ```yaml
  schedule:
    - cron: '0 6 * * *'  # 6:00 UTC t√§glich
  ```

## ‚úÖ FERTIG!

Wenn alle Punkte abgehakt sind:
- Scraper laufen t√§glich automatisch um 6:00 UTC
- Daten werden automatisch zu GitHub gepusht
- GitHub Pages wird automatisch aktualisiert
- Deck Viewer ist live unter captheavenger.github.io/HausiTCG

---

## üêõ Fehlerbehandlung:

**Falls Workflow fehlschl√§gt:**
1. Gehe zu: https://github.com/captheavenger/HausiTCG/actions
2. Klick auf fehlgeschlagenen Workflow
3. Schau dir den Log an (meist unten)
4. H√§ufige Fehler:
   - ‚ùå Python/Dependencies nicht installiert ‚Üí Behebe in Workflow
   - ‚ùå Module nicht gefunden ‚Üí √úberpr√ºfe Pfade
   - ‚ùå Git-Authentifizierung fehlgeschlagen ‚Üí √úberpr√ºfe Token

**Falls Bilder nicht laden:**
1. √úberpr√ºfe dass URLs aus unified_card_data.csv Limitless CDN Format haben
2. Format sollte sein: `https://limitlesstcg.nyc3.cdn.digitaloceanspaces.com/tpci/{SET}/{SET}_{NUM}_{RARITY}_EN_LG.png`
3. Wenn nicht: F√ºhre `update_images.py` lokal aus und pushe updated CSV
